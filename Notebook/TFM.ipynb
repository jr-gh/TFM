{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9831b077",
   "metadata": {},
   "source": [
    "# FASE 1\n",
    "\n",
    "## Descarga de las imágenes que formarán el dataset de pruebas de la APP. Se descargarán las imagenes que contienen una sola persona y un número mínimo de XX keypoints para esa persona\n",
    "\n",
    "## Creación de un fichero en formato JSON con la información de los keypoints de la imagenes descargadas para la posterior comprobación de la precisión de las estimación realizadas por los modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2396362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Iniciado procesado del dataset\n",
      "--------------------------------------------------\n",
      "loading annotations into memory...\n",
      "Done (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "\n",
      "Id de la categoría \"person\":  [1]\n",
      "Número de imágenes pertenecientes a la categoría \"person\":  2693\n",
      "Anotaciones totales para las imágenes de la categoría \"person\" (por numero total de ids):  11004\n",
      "Anotaciones totales para las imágenes de la categoría \"person\" (cargadas del fichero json):  11004\n",
      "Número de imágenes con una sola persona:  1045\n",
      "Número de imágenes con una sola persona filtradas (tienen al menos un keypoint):  887\n",
      "Número de líneas de información de imágenes para el fichero de validación:  887\n",
      "\n",
      "\n",
      "Descargando imágenes del dataset...\n",
      "Descargando imagenes...Finalizado\n",
      "\n",
      "\n",
      "Creando fichero de validación...\n",
      "Creando fichero de validación...Finalizado\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Finalizado procesado del dataset\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('--------------------------------------------------')\n",
    "print('Iniciado procesado del dataset')\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# Cargamos la información de los keypoints de las personas\n",
    "personKeypointsVal2017File = './annotations_train-val/person_keypoints_val2017.json'\n",
    "personKeypointsVal2017COCO = COCO(personKeypointsVal2017File)\n",
    "\n",
    "# Obtenemos el identificador de la categoria de personas\n",
    "personCategoryId = personKeypointsVal2017COCO.getCatIds(catNms=['person'])\n",
    "\n",
    "# Obtenemos los identificadores de las imágenes en la categoria de personas\n",
    "personCategoryImagesIds = personKeypointsVal2017COCO.getImgIds(catIds=personCategoryId)\n",
    "\n",
    "# Obtenemos las anotaciones (contienen los keypoints) de las imágenes de personas\n",
    "personCategoryAnnotationIds = personKeypointsVal2017COCO.getAnnIds(imgIds=personCategoryImagesIds, catIds=personCategoryId, iscrowd=None)  # iscrowd == 0\n",
    "personCategoryAnnotations = personKeypointsVal2017COCO.loadAnns(personCategoryAnnotationIds)\n",
    "\n",
    "# Array para almacenar los identificadores de las imágenes temporalmente\n",
    "imageIdsTemp = []\n",
    "# Array para almacenar los identificadores de las imágenes únicas\n",
    "singlePersonImageIds = []\n",
    "# Array para almacenar los elementos con anotaciones duplicadas\n",
    "multiPersonImageIds = []\n",
    "# Filtramos la lista para quedarnos con las imágenes que solo tienen una anotación (tienen sólo una persona en la imagen)\n",
    "for annotationTemp in personCategoryAnnotations:\n",
    "    # Metemos el id de cada imagen con alguna anotación en imageIdsTemp\n",
    "    if annotationTemp['image_id'] not in imageIdsTemp:\n",
    "        imageIdsTemp.append(annotationTemp['image_id'])\n",
    "    else:\n",
    "        # Metemos el id de cada imagen con mas de una anotación en multiPersonImageIds (sólo una vez)\n",
    "        if annotationTemp['image_id'] not in multiPersonImageIds:\n",
    "            multiPersonImageIds.append(annotationTemp['image_id'])\n",
    "\n",
    "# Nos quedamos con los ids de las imágenes únicas que no tienen ningun id duplicado (anotación duplicada)\n",
    "for idImageTemp in imageIdsTemp:\n",
    "    if idImageTemp not in multiPersonImageIds:\n",
    "        singlePersonImageIds.append(idImageTemp)\n",
    "\n",
    "\n",
    "# Cargamos las anotaciones de esas imágenes con una anotación unica (tienen sólo una persona en la imagen)\n",
    "singlePersonAnnotationIds = personKeypointsVal2017COCO.getAnnIds(imgIds=singlePersonImageIds, catIds=personCategoryId, iscrowd=None)\n",
    "singlePersonAnnotations = personKeypointsVal2017COCO.loadAnns(singlePersonAnnotationIds)\n",
    "\n",
    "# Array para almacenar los identificadores de las imagenes con una sola persona y al menos un keypoint de esa persona\n",
    "singlePersonAnnotationFilteredIds = []\n",
    "# Array para almacenar las lineas del fichero formato json que contendra la información de validación de las imánes del dataset\n",
    "jsonFileLines = []\n",
    "\n",
    "# Filtramos las imágenes que tienen al menos 1 keypoint en su anotacion\n",
    "# - crear una lista de identificadores de las imágenes a descargar\n",
    "# - crear una lista con las lineas con la información de keypoints de cada imagen para el fichero de validación\n",
    "for annotationTemp in singlePersonAnnotations:\n",
    "#    if annotationTemp['num_keypoints'] > 10 and annotationTemp['num_keypoints'] <= 17:          # 614 imágenes con 10-17 puntos\n",
    "    if annotationTemp['num_keypoints'] > 1:                                                      # 887 imágenes con algún punto\n",
    "\n",
    "        # Identificador de la imagen\n",
    "        imageIdTemp = annotationTemp['image_id']\n",
    "\n",
    "        # Añadimos el identificador de la imagen que vamos a descargar al array de identificadores filtrados\n",
    "        singlePersonAnnotationFilteredIds.append(imageIdTemp)                                               \n",
    "\n",
    "        # Añadimos la inea de información para el fichero json de validación al array de lineas\n",
    "        # - añadimos el identificador de la imagen con el formato json correspondiente\n",
    "        jsonFileLineTemp = '{\"image_id\":' + str(imageIdTemp) + ',\"category_id\":1,\"keypoints\":['\n",
    "        # - añadimos los 17 keypoints de la imagen separados por comas\n",
    "        for indexTemp in range(17):\n",
    "            index_x = (indexTemp * 3)\n",
    "            index_Y = (indexTemp * 3) + 1\n",
    "            index_2 = (indexTemp * 3) + 2\n",
    "            jsonFileLineTemp = jsonFileLineTemp + str(annotationTemp['keypoints'][index_x]) + ',' + str(annotationTemp['keypoints'][index_Y]) + ',' + str(annotationTemp['keypoints'][index_2])\n",
    "            if indexTemp < 16:\n",
    "                jsonFileLineTemp = jsonFileLineTemp + ','\n",
    "        # Añadimos la finalización de la linea con la información de la imagen\n",
    "        jsonFileLineTemp = jsonFileLineTemp + '], \"score\":0}'\n",
    "        # Añadimos la linea con la información de la imagen para posteriormente generar el fichero en disco\n",
    "        jsonFileLines.append(jsonFileLineTemp)\n",
    "    \n",
    "    \n",
    "# Impresión de datos para seguimiento\n",
    "print('\\n')\n",
    "print('Id de la categoría \"person\": ', personCategoryId)\n",
    "print('Número de imágenes pertenecientes a la categoría \"person\": ', len(personCategoryImagesIds))\n",
    "print('Anotaciones totales para las imágenes de la categoría \"person\" (por numero total de ids): ', len(personCategoryAnnotationIds))\n",
    "print('Anotaciones totales para las imágenes de la categoría \"person\" (cargadas del fichero json): ', len(personCategoryAnnotations))\n",
    "print('Número de imágenes con una sola persona: ', len(singlePersonImageIds))\n",
    "print('Número de imágenes con una sola persona filtradas (tienen al menos un keypoint): ', len(singlePersonAnnotationFilteredIds))\n",
    "print('Número de líneas de información de imágenes para el fichero de validación: ', len(jsonFileLines))\n",
    "\n",
    "\n",
    "# Creamos la carpeta para el dataset\n",
    "Path('./Dataset').mkdir(parents=True, exist_ok=True)\n",
    "# Creamos la carpeta para las imágenes del dataset\n",
    "Path('./Dataset/Images').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "########################################################################################################################\n",
    "# DESCOMENTAR PARA EJECUTAR LA DESCARGA DE LAS IMAGENES Y LA CREACION DEL FICHERO CSV CON LA INFORMACION DE KEYPOINTS\n",
    "########################################################################################################################\n",
    "\n",
    "print('\\n')\n",
    "print('Descargando imágenes del dataset...')\n",
    "# Descargamos en local las imágenes filtradas (aquellas que tienen una sola persona con al menos un keypoint en sus anotaciones)\n",
    "imagesTemp = personKeypointsVal2017COCO.loadImgs(singlePersonAnnotationFilteredIds)\n",
    "for imageTemp in imagesTemp:\n",
    "    img_data = requests.get(imageTemp['coco_url']).content\n",
    "    with open('./Dataset/Images/' + imageTemp['file_name'], 'wb') as handler:\n",
    "        handler.write(img_data)\n",
    "print('Descargando imagenes del dataset...Finalizado')\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "print('\\n')\n",
    "print('Creando fichero de validación...')\n",
    "\n",
    "# Creamos un fichero json con los datos en formato adaptado para la comprobación de la validación de resultados\n",
    "# Variable índice\n",
    "indexTemp = 0\n",
    "# Variable para el control de separadores (comas a añadir entre cada linea de información de cada imagen)\n",
    "jsonLinesLength = len(jsonFileLines) - 1\n",
    "\n",
    "# Recorremos la estructura con las lineas que hemos generado anteriormente para cada imagen filtrada\n",
    "with open(\"./Dataset/DatasetValidationInfo.json\", \"wt\") as f:\n",
    "    # Escribimos el caracter de inicio de la estructura json\n",
    "    f.write('[')\n",
    "    # Escribimos cada linea generada de cada imagen anteriormente\n",
    "    for jsonFileLineTemp in jsonFileLines:\n",
    "        f.write(jsonFileLineTemp)\n",
    "        # Escribimos los separadores cuando corresponde\n",
    "        if indexTemp < jsonLinesLength:\n",
    "            f.write(',')\n",
    "        # Escribimos un retorno se linea\n",
    "        f.write('\\n')\n",
    "        \n",
    "        indexTemp = indexTemp + 1\n",
    "    # Escribimos el caracter de finalización de la estructura json\n",
    "    f.write(']')\n",
    "\n",
    "print('Creando fichero de validación...Finalizado')\n",
    "\n",
    "print('\\n')\n",
    "print('--------------------------------------------------')\n",
    "print('Finalizado procesado del dataset')\n",
    "print('--------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377f15f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
